{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of base training File =  (20000, 6)\n",
      "Shape of base training data after cleaning =  (20000, 6)\n",
      "Shape of test data (400, 6)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def read_data():\n",
    "    df = pd.read_csv(\"input/train.csv\", nrows=20000)\n",
    "    print (\"Shape of base training File = \", df.shape)\n",
    "    # Remove missing values and duplicates from training data\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    df.dropna(inplace=True)\n",
    "    print(\"Shape of base training data after cleaning = \", df.shape)\n",
    "    return df\n",
    "\n",
    "df = read_data()\n",
    "df_train, df_test = train_test_split(df, test_size = 0.02)\n",
    "print (\"Shape of test data\", df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8164</th>\n",
       "      <td>8164</td>\n",
       "      <td>15923</td>\n",
       "      <td>15924</td>\n",
       "      <td>How many oceans are there on Earth? What are t...</td>\n",
       "      <td>What would happen if the Earth stopped rotating?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13405</th>\n",
       "      <td>13405</td>\n",
       "      <td>25745</td>\n",
       "      <td>25746</td>\n",
       "      <td>Why is the second electron affinity value of o...</td>\n",
       "      <td>Where does the energy that is released from an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18229</th>\n",
       "      <td>18229</td>\n",
       "      <td>34544</td>\n",
       "      <td>34545</td>\n",
       "      <td>How come that the Hindu festival \"Makar Sankra...</td>\n",
       "      <td>Why does VHP want to exclude non-Hindu’s from ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8179</th>\n",
       "      <td>8179</td>\n",
       "      <td>15951</td>\n",
       "      <td>15952</td>\n",
       "      <td>I haven't been accepted to any university in m...</td>\n",
       "      <td>What makes an extraordinary college applicatio...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5744</th>\n",
       "      <td>5744</td>\n",
       "      <td>11288</td>\n",
       "      <td>11289</td>\n",
       "      <td>What is the analog of insulin receptors/signal...</td>\n",
       "      <td>How do I make rice yeast at home?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id   qid1   qid2                                          question1  \\\n",
       "8164    8164  15923  15924  How many oceans are there on Earth? What are t...   \n",
       "13405  13405  25745  25746  Why is the second electron affinity value of o...   \n",
       "18229  18229  34544  34545  How come that the Hindu festival \"Makar Sankra...   \n",
       "8179    8179  15951  15952  I haven't been accepted to any university in m...   \n",
       "5744    5744  11288  11289  What is the analog of insulin receptors/signal...   \n",
       "\n",
       "                                               question2  is_duplicate  \n",
       "8164    What would happen if the Earth stopped rotating?             0  \n",
       "13405  Where does the energy that is released from an...             0  \n",
       "18229  Why does VHP want to exclude non-Hindu’s from ...             0  \n",
       "8179   What makes an extraordinary college applicatio...             0  \n",
       "5744                   How do I make rice yeast at home?             0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\chels\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of words in the dictionary = 4837\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import *\n",
    "import warnings  \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "words = re.compile(r\"\\w+\",re.I)\n",
    "stopword = stopwords.words('english')\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def tokenize_questions(df):\n",
    "    question_1_tokenized = []\n",
    "    question_2_tokenized = []\n",
    "\n",
    "    for q in df.question1.tolist():\n",
    "        question_1_tokenized.append([stemmer.stem(i.lower()) for i in words.findall(q) if i not in stopword])\n",
    "\n",
    "    for q in df.question2.tolist():\n",
    "        question_2_tokenized.append([stemmer.stem(i.lower()) for i in words.findall(q) if i not in stopword])\n",
    "\n",
    "    df[\"Question_1_tok\"] = question_1_tokenized\n",
    "    df[\"Question_2_tok\"] = question_2_tokenized\n",
    "    \n",
    "    return df\n",
    "\n",
    "def train_dictionary(df):\n",
    "    \n",
    "    questions_tokenized = df.Question_1_tok.tolist() + df.Question_2_tok.tolist()\n",
    "    \n",
    "    dictionary = corpora.Dictionary(questions_tokenized)\n",
    "    dictionary.filter_extremes(no_below=5, no_above=0.8)\n",
    "    dictionary.compactify()\n",
    "    \n",
    "    return dictionary\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "df_train = tokenize_questions(df_train)\n",
    "dictionary = train_dictionary(df_train)\n",
    "print (\"No of words in the dictionary = %s\" %len(dictionary.token2id))\n",
    "\n",
    "df_test = tokenize_questions(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19600, 4837)\n",
      "(19600, 4837)\n"
     ]
    }
   ],
   "source": [
    "def get_vectors(df, dictionary):\n",
    "    \n",
    "    question1_vec = [dictionary.doc2bow(text) for text in df.Question_1_tok.tolist()]\n",
    "    question2_vec = [dictionary.doc2bow(text) for text in df.Question_2_tok.tolist()]\n",
    "    \n",
    "    question1_csc = gensim.matutils.corpus2csc(question1_vec, num_terms=len(dictionary.token2id))\n",
    "    question2_csc = gensim.matutils.corpus2csc(question2_vec, num_terms=len(dictionary.token2id))\n",
    "    \n",
    "    return question1_csc.transpose(),question2_csc.transpose()\n",
    "\n",
    "\n",
    "q1_csc, q2_csc = get_vectors(df_train, dictionary)\n",
    "\n",
    "print (q1_csc.shape)\n",
    "print (q2_csc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine_sim sample= \n",
      " [0.3333333333333334, 0.18257418583505539]\n",
      "manhattan_dis sample = \n",
      " [8.0, 9.0]\n",
      "eucledian_dis sample = \n",
      " [2.8284271247461903, 3.0]\n",
      "jaccard_dis sample = \n",
      " [0.2, 0.1]\n",
      "minkowsk_dis sample = \n",
      " [2.8284271247461903, 3.0]\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity as cs\n",
    "from sklearn.metrics.pairwise import manhattan_distances as md\n",
    "from sklearn.metrics.pairwise import euclidean_distances as ed\n",
    "from sklearn.metrics import jaccard_similarity_score as jsc\n",
    "from sklearn.neighbors import DistanceMetric\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "minkowski_dis = DistanceMetric.get_metric('minkowski')\n",
    "mms_scale_man = MinMaxScaler()\n",
    "mms_scale_euc = MinMaxScaler()\n",
    "mms_scale_mink = MinMaxScaler()\n",
    "\n",
    "def get_similarity_values(q1_csc, q2_csc):\n",
    "    cosine_sim = []\n",
    "    manhattan_dis = []\n",
    "    eucledian_dis = []\n",
    "    jaccard_dis = []\n",
    "    minkowsk_dis = []\n",
    "    \n",
    "    for i,j in zip(q1_csc, q2_csc):\n",
    "        sim = cs(i,j)\n",
    "        cosine_sim.append(sim[0][0])\n",
    "        sim = md(i,j)\n",
    "        manhattan_dis.append(sim[0][0])\n",
    "        sim = ed(i,j)\n",
    "        eucledian_dis.append(sim[0][0])\n",
    "        i_ = i.toarray()\n",
    "        j_ = j.toarray()\n",
    "        try:\n",
    "            sim = jsc(i_,j_)\n",
    "            jaccard_dis.append(sim)\n",
    "        except:\n",
    "            jaccard_dis.append(0)\n",
    "            \n",
    "        sim = minkowski_dis.pairwise(i_,j_)\n",
    "        minkowsk_dis.append(sim[0][0])\n",
    "    \n",
    "    return cosine_sim, manhattan_dis, eucledian_dis, jaccard_dis, minkowsk_dis    \n",
    "\n",
    "\n",
    "# cosine_sim = get_cosine_similarity(q1_csc, q2_csc)\n",
    "cosine_sim, manhattan_dis, eucledian_dis, jaccard_dis, minkowsk_dis = get_similarity_values(q1_csc, q2_csc)\n",
    "print (\"cosine_sim sample= \\n\", cosine_sim[0:2])\n",
    "print (\"manhattan_dis sample = \\n\", manhattan_dis[0:2])\n",
    "print (\"eucledian_dis sample = \\n\", eucledian_dis[0:2])\n",
    "print (\"jaccard_dis sample = \\n\", jaccard_dis[0:2])\n",
    "print (\"minkowsk_dis sample = \\n\", minkowsk_dis[0:2])\n",
    "\n",
    "eucledian_dis_array = np.array(eucledian_dis).reshape(-1,1)\n",
    "manhattan_dis_array = np.array(manhattan_dis).reshape(-1,1)\n",
    "minkowsk_dis_array = np.array(minkowsk_dis).reshape(-1,1)\n",
    "    \n",
    "manhattan_dis_array = mms_scale_man.fit_transform(manhattan_dis_array)\n",
    "eucledian_dis_array = mms_scale_euc.fit_transform(eucledian_dis_array)\n",
    "minkowsk_dis_array = mms_scale_mink.fit_transform(minkowsk_dis_array)\n",
    "\n",
    "eucledian_dis = eucledian_dis_array.flatten()\n",
    "manhattan_dis = manhattan_dis_array.flatten()\n",
    "minkowsk_dis = minkowsk_dis_array.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The calculated log loss value on the test set for cosine sim is = 0.960730\n",
      "The calculated log loss value on the test set for manhattan sim is = 2.208167\n",
      "The calculated log loss value on the test set for euclidean sim is = 1.830286\n",
      "The calculated log loss value on the test set for jaccard sim is = 2.820795\n",
      "The calculated log loss value on the test set for minkowski sim is = 1.830286\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "def calculate_logloss(y_true, y_pred):\n",
    "    loss_cal = log_loss(y_true, y_pred)\n",
    "    return loss_cal\n",
    "\n",
    "q1_csc_test, q2_csc_test = get_vectors(df_test, dictionary)\n",
    "y_pred_cos, y_pred_man, y_pred_euc, y_pred_jac, y_pred_mink = get_similarity_values(q1_csc_test, q2_csc_test)\n",
    "y_true = df_test.is_duplicate.tolist()\n",
    "\n",
    "y_pred_man_array = mms_scale_man.transform(np.array(y_pred_man).reshape(-1,1))\n",
    "y_pred_man = y_pred_man_array.flatten()\n",
    "\n",
    "y_pred_euc_array = mms_scale_euc.transform(np.array(y_pred_euc).reshape(-1,1))\n",
    "y_pred_euc = y_pred_euc_array.flatten()\n",
    "\n",
    "y_pred_mink_array = mms_scale_mink.transform(np.array(y_pred_mink).reshape(-1,1))\n",
    "y_pred_mink = y_pred_mink_array.flatten()\n",
    "\n",
    "logloss = calculate_logloss(y_true, y_pred_cos)\n",
    "print (\"The calculated log loss value on the test set for cosine sim is = %f\" %logloss)\n",
    "\n",
    "logloss = calculate_logloss(y_true, y_pred_man)\n",
    "print (\"The calculated log loss value on the test set for manhattan sim is = %f\" %logloss)\n",
    "\n",
    "logloss = calculate_logloss(y_true, y_pred_euc)\n",
    "print (\"The calculated log loss value on the test set for euclidean sim is = %f\" %logloss)\n",
    "\n",
    "logloss = calculate_logloss(y_true, y_pred_jac)\n",
    "print (\"The calculated log loss value on the test set for jaccard sim is = %f\" %logloss)\n",
    "\n",
    "logloss = calculate_logloss(y_true, y_pred_mink)\n",
    "print (\"The calculated log loss value on the test set for minkowski sim is = %f\" %logloss)"
   ]
  }
 ],
 "metadata": {
  "_change_revision": 0,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
